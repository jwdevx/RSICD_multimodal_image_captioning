Expect output in this folder:
    â”œâ”€â”€ best_model/
    â”‚   â”‚
    â”‚   â”œâ”€â”€ config.json (Configuration file for the decoder)
    â”‚   â”œâ”€â”€ preprocessor_config.json (Preprocessing config from BlipProcessor)
    â”‚   â”œâ”€â”€ pytorch_model.bin (Model weights of the fine-tuned decoder (encoder is frozen))
    â”‚   â”œâ”€â”€ special_tokens_map.json (Mapping of special tokens (e.g. pad, eos))
    â”‚   â”œâ”€â”€ tokenizer_config.json (Tokenizer config from Hugging Face)
    â”‚   â”‚
    â”‚   â”œâ”€â”€ merges.txt (Tokenizer vocab + merge rules (if using BPE/Byte-level models))
    â”‚   â””â”€â”€ vocab.json (Tokenizer vocab + merge rules (if using BPE/Byte-level models))
    â”‚
    â”œâ”€â”€ training_log.txt (Console + file logs for each epoch: loss, warnings, generation samples, etc)
    â”œâ”€â”€ generated_captions_epoch*.json (1 .. n)
    â”œâ”€â”€ sample_logs_epoch1.txt (In-depth sample logging)

Pretraining the ability to
    - ðŸ“‰ loss and accuracy curves
    - ðŸ“Š Plot accuracy curve
    - ðŸ§  Manual compare caption between ground truth and generated